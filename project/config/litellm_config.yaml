model_list:
  - model_name: llama3.1
    litellm_provider: ollama
    litellm_params:
      model: llama3.1
      api_base: http://host.docker.internal:11434

litellm_settings:
  set_verbose: true
  drop_params: true
  test_flag_to_check_logs: true